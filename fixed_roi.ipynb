{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66341bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘‰ Left-click to add ROI points, ENTER to save, ESC to cancel\n",
      "âœ… ROI points saved: [(435, 65), (483, 65), (486, 162), (434, 160)]\n",
      "âœ… Finished! Video saved as output.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# -----------------\n",
    "# STEP 1: Select ROI from first video frame\n",
    "# -----------------\n",
    "roi_points = []\n",
    "\n",
    "def draw_points(event, x, y, flags, param):\n",
    "    global roi_points, frame_copy\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        roi_points.append((x, y))\n",
    "        cv2.circle(frame_copy, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow(\"ROI Selector\", frame_copy)\n",
    "\n",
    "# Load video and capture first frame\n",
    "video_path = \"/Users/farahalhanaya/computer-vision-project-mawqif/models_training/istockphoto-845341376-640_adpp_is.mp4\"  # change this\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "frame_copy = frame.copy()\n",
    "cv2.imshow(\"ROI Selector\", frame_copy)\n",
    "cv2.setMouseCallback(\"ROI Selector\", draw_points)\n",
    "\n",
    "print(\"ðŸ‘‰ Left-click to add ROI points, ENTER to save, ESC to cancel\")\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey(0)\n",
    "    if key == 13:  # ENTER key\n",
    "        break\n",
    "    elif key == 27:  # ESC key\n",
    "        roi_points = []\n",
    "        print(\"âŒ ROI selection cancelled\")\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save ROI points\n",
    "if roi_points:\n",
    "    with open(\"roi_points.json\", \"w\") as f:\n",
    "        json.dump(roi_points, f)\n",
    "    print(\"âœ… ROI points saved:\", roi_points)\n",
    "\n",
    "    # Show ROI drawn\n",
    "    roi_preview = frame.copy()\n",
    "    cv2.polylines(roi_preview, [np.array(roi_points, np.int32)], True, (0, 0, 255), 3)\n",
    "    cv2.imshow(\"ROI Preview\", roi_preview)\n",
    "    cv2.waitKey(2000)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No ROI saved, exiting...\")\n",
    "    exit()\n",
    "\n",
    "# -----------------\n",
    "# STEP 2: Load trained model\n",
    "# -----------------\n",
    "\n",
    "def load_model(weights_path=\"/Users/farahalhanaya/computer-vision-project-mawqif/faster_rcnn_car (1).pth\"):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=None)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
    "        in_features, num_classes=2\n",
    "    )\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_model(\"/Users/farahalhanaya/computer-vision-project-mawqif/faster_rcnn_car (1).pth\")\n",
    "\n",
    "# -----------------\n",
    "# Helper: ROI violation check\n",
    "# -----------------\n",
    "def check_roi_overlap(roi_points, car_box, H, W, threshold=0.2):\n",
    "    mask = np.zeros((H, W), dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [roi_points], 255)\n",
    "\n",
    "    car_mask = np.zeros((H, W), dtype=np.uint8)\n",
    "    x1, y1, x2, y2 = map(int, car_box)\n",
    "    cv2.rectangle(car_mask, (x1, y1), (x2, y2), 255, -1)\n",
    "\n",
    "    intersection = cv2.bitwise_and(mask, car_mask)\n",
    "    inter_area = cv2.countNonZero(intersection)\n",
    "    car_area = (x2 - x1) * (y2 - y1)\n",
    "    return inter_area / car_area > threshold\n",
    "\n",
    "# -----------------\n",
    "# STEP 3: Process video with ROI\n",
    "# -----------------\n",
    "with open(\"roi_points.json\") as f:\n",
    "    roi_points = np.array(json.load(f), dtype=np.int32)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "out = cv2.VideoWriter(\"output.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 20.0,\n",
    "                      (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "transform = T.ToTensor()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    H, W = frame.shape[:2]\n",
    "\n",
    "    # Run detection\n",
    "    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    img_tensor = transform(img)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model([img_tensor])\n",
    "\n",
    "    boxes = outputs[0][\"boxes\"].numpy()\n",
    "    scores = outputs[0][\"scores\"].numpy()\n",
    "    labels = outputs[0][\"labels\"].numpy()\n",
    "\n",
    "    # Draw ROI\n",
    "    cv2.polylines(frame, [roi_points], True, (0, 0, 255), 3)\n",
    "\n",
    "    # Draw detections\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        if score > 0.5 and label == 1:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            violation = check_roi_overlap(roi_points, box, H, W)\n",
    "            color = (0, 0, 255) if violation else (0, 255, 0)\n",
    "            status = \"Violation\" if violation else \"OK\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f\"{status} {score:.2f}\", (x1, y1 - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    out.write(frame)\n",
    "    cv2.imshow(\"Video Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"âœ… Finished! Video saved as output.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed2ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
